# Pyspark

# What is Pyspark

* PySpark has been released in order to support the collaboration of Apache Spark and Python, it actually is a Python API for Spark. 

* In addition, PySpark, helps you interface with Resilient Distributed Datasets (RDDs) in Apache Spark and Python programming language.

# Pyspark Sql

* PySpark SQL is a module in Spark which integrates relational processing with Spark's functional programming API. 

* We can extract the data by using an SQL query language. We can use the queries same as the SQL language.

# Pyspark Tutorial 1

* Installation
* SparkSession
* Reading the Dataset
* Working with Datasets

# Pyspark Tutorial 2

* Dealing with Null Values
* Filter Operation
* GroupBy and Aggregate Functions
